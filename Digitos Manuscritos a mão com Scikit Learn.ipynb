{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdu√ß√£o\n",
    "\n",
    "Este material √© uma tradu√ß√£o do Tutorial preparado por Colin Bernet que pode ser acessado [aqui ](https://thedatafrog.com/handwritten-digit-recognition-scikit-learn/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre este tutorial\n",
    "\n",
    "Este tutorial √© uma introdu√ß√£o pr√°tica ao aprendizado de m√°quina para iniciantes.\n",
    "\n",
    "A introdu√ß√£o ao aprendizado de m√°quina pode ser bastante dif√≠cil quando voc√™ procura aleatoriamente informa√ß√µes na web.\n",
    "\n",
    "Aqui, meu objetivo √© ajud√°-lo com um exemplo concreto de reconhecimento de imagem, com apenas um pouco de c√≥digo e sem matem√°tica.\n",
    "\n",
    "Ap√≥s uma breve introdu√ß√£o ao aprendizado de m√°quina, voc√™ aprender√°:\n",
    "\n",
    "* os princ√≠pios do aprendizado de m√°quina supervisionado para classifica√ß√£o,\n",
    "* como instalar todo o pacote cient√≠fico do python,\n",
    "* como acessar e validar os dados de treinamento para sua rede,\n",
    "* como criar e treinar sua rede\n",
    "* como usar o treinado e testar seu desempenho.\n",
    "\n",
    "#### Pr√©-requisitos\n",
    "\n",
    "Trabalharemos em python, que √© uma escolha maravilhosa para a ci√™ncia de dados. Se voc√™ n√£o √© um desenvolvedor python, mas conhece um pouco de C, C ++ ou Java, por exemplo, ficar√° bem. Essa ser√° uma excelente ocasi√£o para descobrir python. E, quem sabe, voc√™ tamb√©m pode se apaixonar por essa linguagem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por que aprendizado de m√°quina?\n",
    "\n",
    "O aprendizado de m√°quina √© um campo de intelig√™ncia artificial no qual um sistema √© projetado para aprender automaticamente, considerando um conjunto de dados de entrada. Ap√≥s o aprendizado do sistema (dizemos que o sistema foi treinado), podemos us√°-lo para fazer previs√µes de novos dados, antes nunca vistos.\n",
    "\n",
    "Essa abordagem torna poss√≠vel solucionar problemas complexos dif√≠ceis ou imposs√≠veis de resolver com a programa√ß√£o seq√ºencial tradicional.\n",
    "\n",
    "Exemplos de aplicativos de aprendizado de m√°quina incluem:\n",
    "\n",
    "* carros aut√¥nomos: dados os dados de sensores como c√¢meras e radares, o carro √© treinado para dirigir por conta pr√≥pria.\n",
    "\n",
    "[O site do google ainda precisa aprender sobre a faixa da direita] (https://www.youtube.com/watch?v=TsaES--OTzM) ;-)\n",
    "* drones: o piloto do drone s√≥ precisa dar instru√ß√µes simples (para cima, baixo, esquerda, direita ou apenas coordenadas 3D), e o drone executa automaticamente ajustes complexos para manter a estabilidade ou para voar em forma√ß√£o (https: // www.youtube.com/watch?v=VnTQTm7vNbY)\n",
    "* [rob√¥s](https://www.youtube.com/watch?v=LikxFZZO2sk)\n",
    "* previs√£o do pre√ßo do im√≥vel a partir de um conjunto de vari√°veis ‚Äã‚Äãcomo localiza√ß√£o, n√∫mero de quartos e at√© o texto do an√∫ncio imobili√°rio. Certamente farei um tutorial sobre isso em um futuro pr√≥ximo.\n",
    "* an√∫ncios do Google que prev√™em a probabilidade de voc√™ estar interessado em um determinado an√∫ncio para enviar os mais promissores\n",
    "* sistemas de recomenda√ß√£o colaborativa que oferecem os v√≠deos do youtube ou os produtos da amazon que voc√™ vai gostar\n",
    "* identifica√ß√£o de defeitos nas cadeias de produ√ß√£o\n",
    "* identifica√ß√£o de grupos de pessoas afins nas redes sociais e dos influenciadores mais importantes dentro desses grupos\n",
    "* marcar fotos (basta digitar gato ou comida na caixa de pesquisa da sua biblioteca de fotos do Google, se voc√™ tiver uma)\n",
    "* sistemas de tradu√ß√£o como o [google translate](https://translate.google.fr/?hl=en)\n",
    "\n",
    "* filtragem de spam e-mail\n",
    "* gerar pinturas automaticamente:[sonho profundo](https://deepdreamgenerator.com/#gallery), [doodle neural](https://github.com/alexjc/neural-doodle)\n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizado de m√°quina para classifica√ß√£o\n",
    "\n",
    "Vamos entender como uma rede neural pode ser treinada para classifica√ß√£o.\n",
    "\n",
    "Neste post, nosso objetivo √© come√ßar o aprendizado de m√°quina de maneira r√°pida e f√°cil, por isso, s√≥ vou lhe dar uma explica√ß√£o simplificada por enquanto. Haver√° um post mais detalhado sobre os princ√≠pios de treinamento posteriormente, portanto, fique atento se estiver interessado.\n",
    "\n",
    "! [Aprendizado supervisionado] (https://github.com/cbernet/maldives/raw/master/handwritten_digits_sklearn/supervised_learning.png)\n",
    "\n",
    "A rede √© apresentada com uma sucess√£o de exemplos de treinamento. Cada exemplo de treinamento consiste em:\n",
    "\n",
    "* a imagem de um d√≠gito\n",
    "* um r√≥tulo que indica qual d√≠gito a imagem realmente representa. Para uma determinada imagem, o r√≥tulo poderia ser informado pela pessoa que escreveu o d√≠gito em primeiro lugar.\n",
    "\n",
    "No desenho acima, a primeira imagem √© processada pela rede neural, que produz uma resposta: este √© um 9.\n",
    "\n",
    "A princ√≠pio, as conex√µes entre os neur√¥nios da rede s√£o aleat√≥rias e a rede n√£o pode fazer nada de √∫til. Apenas fornece uma resposta aleat√≥ria.\n",
    "\n",
    "A resposta √© comparada ao r√≥tulo. Nesse caso, a resposta (9) √© diferente da etiqueta (o d√≠gito √© na verdade um 3), e algum feedback √© dado √† rede neural para que ela possa melhorar. As conex√µes entre os neur√¥nios s√£o modificadas, favorecendo as que tendem a dar uma resposta correta.\n",
    "\n",
    "Ap√≥s a modifica√ß√£o, os pr√≥ximos exemplos s√£o considerados e a rede neural aprende em um processo iterativo.\n",
    "\n",
    "O n√∫mero de exemplos de treinamento necess√°rios para treinar a rede corretamente pode ser da ordem de algumas centenas para redes com uma arquitetura simples e milh√µes para redes complexas.\n",
    "\n",
    "## Instalando python e sua biblioteca cient√≠fica\n",
    "\n",
    "** Se voc√™ j√° est√° executando este tutorial em seu notebook jupyter, pule esta se√ß√£o. **\n",
    "\n",
    "Usaremos uma variedade de ferramentas da [scipy](https://www.scipy.org/), a biblioteca cient√≠fica python:\n",
    "\n",
    "* [scikit-learn](https://scikit-learn.org/): um dos principais kits de ferramentas de aprendizado de m√°quina para python. Ele fornecer√° um acesso f√°cil ao conjunto de dados de d√≠gitos manuscritos e nos permitir√° definir e treinar nossa rede neural em algumas linhas de c√≥digo\n",
    "* [numpy](http://www.numpy.org/): pacote principal que fornece ferramentas poderosas para manipular matrizes de dados, como nossas imagens de d√≠gitos\n",
    "* [matplotlib](https://matplotlib.org/): ferramentas de visualiza√ß√£o, essenciais para verificar o que estamos fazendo\n",
    "* [jupyter](https://jupyter.org/): o servidor da web que permitir√° que voc√™ siga este tutorial e execute o c√≥digo diretamente no seu navegador.\n",
    "\n",
    "O Scipy, na verdade, n√£o √© uma biblioteca √∫nica, mas um \"ecossistema\" de pacotes python interdependentes.\n",
    "\n",
    "Esse ecossistema est√° cheio de cobras e bestas que lutam pela sobreviv√™ncia - voc√™ n√£o quer ficar l√° sozinho.\n",
    "\n",
    "E, de fato, seis anos atr√°s, quando eu comecei com o scipy, tentei instalar manualmente todos os pacotes necess√°rios na parte superior da vers√£o do python j√° instalada no meu sistema.\n",
    "\n",
    "Passei quase um dia lutando contra depend√™ncias conflitantes para esses pacotes. Por exemplo, o scikit-learn pode precisar da vers√£o numpy A, mas o pandas precisa da vers√£o B numpy. Ou um desses pacotes requer uma vers√£o do python mais recente que a sua, o que significa que voc√™ precisa instalar uma vers√£o adicional do python e lide com suas duas vers√µes mais tarde.\n",
    "\n",
    "E ent√£o, eu descobri o [Anaconda] (https://anaconda.org/).\n",
    "\n",
    "Conforme declarado no site da Anaconda:\n",
    "\n",
    "* Com mais de 6 milh√µes de usu√°rios, o Anaconda Distribution de c√≥digo aberto √© a maneira mais r√°pida e f√°cil de fazer ci√™ncia de dados em Python e R e aprendizado de m√°quina no Linux, Windows e Mac OS X. √â o padr√£o do setor para desenvolvimento, teste e treinamento em uma √∫nica m√°quina. *\n",
    "\n",
    "Em poucas palavras, a equipe do anaconda mant√©m um reposit√≥rio de mais de 1400 pacotes de ci√™ncia de dados, todos compat√≠veis, e fornece ferramentas para instalar uma vers√£o do python e esses pacotes com o pressionar de um bot√£o e menos de cinco minutos.\n",
    "\n",
    "Vamos fazer agora!\n",
    "\n",
    "Primeiro, [fa√ßa o download do anaconda] (https://www.anaconda.com/download/) para o seu sistema:\n",
    "\n",
    "* Escolha a vers√£o python 2.X, n√£o a vers√£o 3.X.\n",
    "* Se voc√™ estiver usando o Windows ou Linux, escolha o instalador de 64 bits se tiver um sistema de 64 bits.\n",
    "\n",
    "Execute o instalador e, finalmente, inicie o Anaconda Navigator. No Windows, voc√™ pode encontr√°-lo clicando no bot√£o Iniciar do Windows e digitando anaconda.\n",
    "\n",
    "Na janela Anaconda Navigator, clique na guia In√≠cio e inicie o notebook jupyter.\n",
    "\n",
    "Crie um novo notebook. No seu notebook, voc√™ ver√° uma c√©lula vazia, onde √© poss√≠vel escrever c√≥digo python. Copie e cole as seguintes linhas e execute a c√©lula pressionando Shift + Enter.\n",
    "\n",
    "```python\n",
    "print 'hello world!'\n",
    "for i in range(10):\n",
    "    print i\n",
    "```\n",
    "\n",
    "Uma nova c√©lula aparece. Importe numpy e matplotlib (lembre-se de que voc√™ precisa executar a c√©lula):\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "```\n",
    "\n",
    "Esta √© uma maneira padr√£o de importar estes m√≥dulos:\n",
    "\n",
    "* o m√≥dulo pyplot do matplotlib √© chamado plt neste contexto\n",
    "* o m√≥dulo numpy √© chamado np\n",
    "\n",
    "Voc√™ pode muito bem escolher outros nomes, mas esses s√£o usados por quase todo mundo, por isso √© mais f√°cil us√°-los tamb√©m.\n",
    "\n",
    "Agora vamos tentar fazer nosso primeiro gr√°fico, apenas para garantir que numpy e matplotlib estejam funcionando:\n",
    "\n",
    "```python \n",
    "# create a numpy 1-D array with 16 evenly spaced values, from 0 to 3.\n",
    "x = np.linspace(0, 3, 16)\n",
    "print x \n",
    "# create a new numpy array. \n",
    "# x**2 means that each element of x is squared.\n",
    "y = x**2\n",
    "print y\n",
    "# plot y versus x, you should get a parabola. \n",
    "# check that for x = 1 we have y = 1, and that for x = 2, y = 4. \n",
    "plt.plot(x, y)\n",
    "```\n",
    "\n",
    "--- \n",
    "\n",
    "üí° **Uma palavra de cautela:**\n",
    "\n",
    "√â muito f√°cil se perder na documenta√ß√£o de todas essas ferramentas e perder muito tempo.\n",
    "\n",
    "Por exemplo, se voc√™ verificar a documenta√ß√£o do m√©todo plt.plot (n√£o fornecerei o link ;-) mas voc√™ pode pesquis√°-lo no Google), ver√° que existem v√°rias maneiras de cham√°-lo, com muitos par√¢metros opcionais . Mas, afinal, precisamos saber mais do que isso: `plt.plot (x, y)` plota y vs x?\n",
    "\n",
    "Se voc√™ quiser se divertir, sugiro seguir este tutorial at√© o final sem ir mais fundo.\n",
    "\n",
    "Voc√™ treinar√° sua primeira rede neural com facilidade e, no processo, ter√° uma compreens√£o das ferramentas mais importantes para aprender scikit, numpy e matplotlib. Isso √© mais do que suficiente para uma variedade de tarefas de aprendizado de m√°quina, e voc√™ sempre pode aprender mais sobre os recursos espec√≠ficos dessas ferramentas quando precisar delas mais tarde (voc√™ saber√°!)\n",
    "\n",
    "Para ir al√©m, aqui est√° uma excelente [palestra sobre scipy](https://scipy-lectures.org/).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que voc√™ tem acesso ao notebook jupyter, tenho boas not√≠cias. Voc√™ n√£o precisar√° manter o c√≥digo de copiar e colar desta p√°gina no seu notebook.\n",
    "\n",
    "Em vez disso, fa√ßa o seguinte:\n",
    "\n",
    "* [fa√ßa o download do reposit√≥rio que cont√©m este caderno](https://github.com/cbernet/maldives/archive/master.zip)\n",
    "* descompacte-o, diga `Downloads / maldives-master`\n",
    "* inicie um notebook jupyter a partir do navegador anaconda\n",
    "* no caderno, navegue at√© `Downloads / maldives-master / handwritten_digits_sklearn`\n",
    "* abra `handwritten_digits_sklean.ipynb`\n",
    "\n",
    "Voc√™ deve ver esta p√°gina aparecer no caderno. A partir de agora, siga o tutorial no caderno. Voc√™ deve executar as c√©lulas como elas v√™m, ou execut√°-las de uma s√≥ vez. Voc√™ pode at√© adicionar c√©lulas ou modificar c√©lulas existentes para experimentar um pouco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O conjunto de dados de d√≠gitos\n",
    "\n",
    "O scikit-learn vem com v√°rios conjuntos de dados de teste. Vamos carregar o conjunto de dados de d√≠gitos manuscritos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em python, a fun√ß√£o `dir` retorna os nomes dos atributos de um objeto, ou seja, quais informa√ß√µes s√£o armazenadas no objeto na forma de outros objetos. Vamos usar esta fun√ß√£o para verificar o que pode ser encontrado no objeto d√≠gitos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada em mais detalhes em alguns desses atributos. Vamos come√ßar verificando o tipo deles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(digits.images))\n",
    "print(type(digits.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`images` e` target` s√£o ndarrays (matrizes N-dimensionais) do pacote numpy. O atributo shape de um ndarray fornece o n√∫mero de dimens√µes e o tamanho ao longo de cada dimens√£o da matriz. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "digits.image √© uma matriz com 3 dimens√µes. A primeira dimens√£o indexa imagens e vemos que temos 1797 imagens no total. As pr√≥ximas duas dimens√µes correspondem √†s coordenadas xey dos pixels em cada imagem. Cada imagem tem 8x8 = 64 pixels. Em outras palavras, essa matriz pode ser representada em 3D como uma pilha de imagens com 8x8 pixels cada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vejamos os dados da primeira imagem 8x8. Cada slot na matriz corresponde a um pixel, e o valor no slot √© a quantidade de preto no pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos exibir esta imagem: (√†s vezes, o gr√°fico n√£o aparece, basta executar novamente esta c√©lula se voc√™ n√£o vir a imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digits.images[0],cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A imagem √© de baixa resolu√ß√£o. Os d√≠gitos originais tinham uma resolu√ß√£o muito mais alta e a resolu√ß√£o foi diminu√≠da ao criar o conjunto de dados para o scikit-learn para tornar mais f√°cil e r√°pido o treinamento de um algoritmo de aprendizado de m√°quina para reconhecer esses d√≠gitos.\n",
    "\n",
    "Agora vamos investigar o atributo target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n",
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target.shape)\n",
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â uma matriz unidimensional com 1797 slots. Observando a matriz, vemos que ela cont√©m os n√∫meros verdadeiros correspondentes a cada imagem. Por exemplo, o primeiro alvo √© 0 e corresponde √† imagem desenhada logo acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada em mais algumas imagens usando esta fun√ß√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multi(i):\n",
    "    '''Plota 16 d√≠gitos, come√ßando com o d√≠gito i'''\n",
    "    nplots = 16\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    for j in range(nplots):\n",
    "        plt.subplot(4,4,j+1)\n",
    "        plt.imshow(digits.images[i+j], cmap='binary')\n",
    "        plt.title(digits.target[i+j])\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_multi(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voc√™ pode dar uma olhada nos pr√≥ximos d√≠gitos chamando plot_multi (16), plot_multi (32) etc. Voc√™ provavelmente ver√° que, com uma resolu√ß√£o t√£o baixa, √© muito dif√≠cil reconhecer alguns dos d√≠gitos, mesmo para humanos. Nessas condi√ß√µes, nossa rede neural tamb√©m ser√° limitada pela baixa qualidade das imagens de entrada. A rede neural pode ter um desempenho t√£o bom quanto o humano? J√° seria uma conquista!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo a rede e preparando os dados de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o [scikit-learn](https://scikit-learn.org), a cria√ß√£o, o treinamento e a avalia√ß√£o de uma rede neural podem ser feitos com apenas algumas linhas de c√≥digo.\n",
    "\n",
    "Faremos uma rede neural muito simples, com tr√™s camadas:\n",
    "\n",
    "* uma camada de entrada, com 64 n√≥s, um n√≥ por pixel nas imagens de entrada. N√≥s s√£o neur√¥nios que realmente n√£o fazem nada. Eles apenas pegam seu valor de entrada e o enviam para os neur√¥nios da pr√≥xima camada\n",
    "* uma camada oculta com 15 neur√¥nios. Poder√≠amos escolher um n√∫mero diferente e tamb√©m adicionar mais camadas ocultas com diferentes n√∫meros de neur√¥nios\n",
    "* uma camada de sa√≠da com 10 neur√¥nios correspondentes √†s nossas 10 classes de d√≠gitos, de 0 a 9.\n",
    "\n",
    "Essa √© uma rede neural * densa *, o que significa que cada n√≥ em cada camada est√° conectado a todos os n√≥s nas camadas anterior e seguinte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Simple dense network](https://github.com/cbernet/maldives/raw/master/handwritten_digits_sklearn/simple_dense.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A camada de entrada requer uma matriz unidimensional na entrada, mas nossas imagens s√£o 2D. Ent√£o, precisamos achatar todas as imagens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = digits.target\n",
    "x = digits.images.reshape((len(digits.images), -1))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos 1797 imagens achatadas. As duas dimens√µes de nossas imagens 8x8 foram recolhidas em uma √∫nica dimens√£o, escrevendo as linhas de 8 pixels conforme elas aparecem, uma ap√≥s a outra. A primeira imagem que vimos anteriormente agora √© representada por uma matriz 1-D com 8x8 = 64 slots. Verifique se os valores abaixo s√£o os mesmos da imagem 2-D original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agora vamos dividir nossos dados em uma amostra de treinamento e uma amostra de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:1000]\n",
    "y_train = y[:1000]\n",
    "x_test = x[1000:]\n",
    "y_test = y[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As primeiras 1000 imagens e r√≥tulos ser√£o usadas para treinamento. O restante do conjunto de dados ser√° usado posteriormente para testar o desempenho da nossa rede."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos criar a rede neural. Usamos uma camada oculta com 15 neur√¥nios, e o scikit-learn √© inteligente o suficiente para descobrir quantos n√∫meros usar nas camadas de entrada e sa√≠da. N√£o preste aten√ß√£o nos outros par√¢metros, abordaremos isso em postagens futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(15,), activation='logistic', alpha=1e-4,\n",
    "                    solver='sgd', tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos treinar a rede neural:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.22958289\n",
      "Iteration 2, loss = 1.91207743\n",
      "Iteration 3, loss = 1.62507727\n",
      "Iteration 4, loss = 1.32649842\n",
      "Iteration 5, loss = 1.06100535\n",
      "Iteration 6, loss = 0.83995513\n",
      "Iteration 7, loss = 0.67806075\n",
      "Iteration 8, loss = 0.55175832\n",
      "Iteration 9, loss = 0.45840445\n",
      "Iteration 10, loss = 0.39149735\n",
      "Iteration 11, loss = 0.33676351\n",
      "Iteration 12, loss = 0.29059880\n",
      "Iteration 13, loss = 0.25437208\n",
      "Iteration 14, loss = 0.22838372\n",
      "Iteration 15, loss = 0.20200554\n",
      "Iteration 16, loss = 0.18186565\n",
      "Iteration 17, loss = 0.16461183\n",
      "Iteration 18, loss = 0.14990228\n",
      "Iteration 19, loss = 0.13892154\n",
      "Iteration 20, loss = 0.12833784\n",
      "Iteration 21, loss = 0.12138920\n",
      "Iteration 22, loss = 0.11407971\n",
      "Iteration 23, loss = 0.10677664\n",
      "Iteration 24, loss = 0.10037149\n",
      "Iteration 25, loss = 0.09593187\n",
      "Iteration 26, loss = 0.09250135\n",
      "Iteration 27, loss = 0.08676698\n",
      "Iteration 28, loss = 0.08356043\n",
      "Iteration 29, loss = 0.08209789\n",
      "Iteration 30, loss = 0.07649168\n",
      "Iteration 31, loss = 0.07410898\n",
      "Iteration 32, loss = 0.07126869\n",
      "Iteration 33, loss = 0.06926956\n",
      "Iteration 34, loss = 0.06578496\n",
      "Iteration 35, loss = 0.06374913\n",
      "Iteration 36, loss = 0.06175492\n",
      "Iteration 37, loss = 0.05975664\n",
      "Iteration 38, loss = 0.05764485\n",
      "Iteration 39, loss = 0.05623663\n",
      "Iteration 40, loss = 0.05420966\n",
      "Iteration 41, loss = 0.05413911\n",
      "Iteration 42, loss = 0.05256140\n",
      "Iteration 43, loss = 0.05020265\n",
      "Iteration 44, loss = 0.04902779\n",
      "Iteration 45, loss = 0.04788382\n",
      "Iteration 46, loss = 0.04655532\n",
      "Iteration 47, loss = 0.04586089\n",
      "Iteration 48, loss = 0.04451758\n",
      "Iteration 49, loss = 0.04341598\n",
      "Iteration 50, loss = 0.04238096\n",
      "Iteration 51, loss = 0.04162200\n",
      "Iteration 52, loss = 0.04076839\n",
      "Iteration 53, loss = 0.04003180\n",
      "Iteration 54, loss = 0.03907774\n",
      "Iteration 55, loss = 0.03815565\n",
      "Iteration 56, loss = 0.03791975\n",
      "Iteration 57, loss = 0.03706276\n",
      "Iteration 58, loss = 0.03617874\n",
      "Iteration 59, loss = 0.03593227\n",
      "Iteration 60, loss = 0.03504175\n",
      "Iteration 61, loss = 0.03441259\n",
      "Iteration 62, loss = 0.03397449\n",
      "Iteration 63, loss = 0.03326990\n",
      "Iteration 64, loss = 0.03305025\n",
      "Iteration 65, loss = 0.03244893\n",
      "Iteration 66, loss = 0.03191504\n",
      "Iteration 67, loss = 0.03132169\n",
      "Iteration 68, loss = 0.03079707\n",
      "Iteration 69, loss = 0.03044946\n",
      "Iteration 70, loss = 0.03005546\n",
      "Iteration 71, loss = 0.02960555\n",
      "Iteration 72, loss = 0.02912799\n",
      "Iteration 73, loss = 0.02859103\n",
      "Iteration 74, loss = 0.02825959\n",
      "Iteration 75, loss = 0.02788968\n",
      "Iteration 76, loss = 0.02748725\n",
      "Iteration 77, loss = 0.02721247\n",
      "Iteration 78, loss = 0.02686225\n",
      "Iteration 79, loss = 0.02635636\n",
      "Iteration 80, loss = 0.02607439\n",
      "Iteration 81, loss = 0.02577613\n",
      "Iteration 82, loss = 0.02553642\n",
      "Iteration 83, loss = 0.02518749\n",
      "Iteration 84, loss = 0.02484300\n",
      "Iteration 85, loss = 0.02455379\n",
      "Iteration 86, loss = 0.02432480\n",
      "Iteration 87, loss = 0.02398548\n",
      "Iteration 88, loss = 0.02376004\n",
      "Iteration 89, loss = 0.02341261\n",
      "Iteration 90, loss = 0.02318255\n",
      "Iteration 91, loss = 0.02296065\n",
      "Iteration 92, loss = 0.02274048\n",
      "Iteration 93, loss = 0.02241054\n",
      "Iteration 94, loss = 0.02208181\n",
      "Iteration 95, loss = 0.02190861\n",
      "Iteration 96, loss = 0.02174404\n",
      "Iteration 97, loss = 0.02156939\n",
      "Iteration 98, loss = 0.02119768\n",
      "Iteration 99, loss = 0.02101874\n",
      "Iteration 100, loss = 0.02078230\n",
      "Iteration 101, loss = 0.02061573\n",
      "Iteration 102, loss = 0.02039802\n",
      "Iteration 103, loss = 0.02017245\n",
      "Iteration 104, loss = 0.01997162\n",
      "Iteration 105, loss = 0.01989280\n",
      "Iteration 106, loss = 0.01963828\n",
      "Iteration 107, loss = 0.01941850\n",
      "Iteration 108, loss = 0.01933154\n",
      "Iteration 109, loss = 0.01911473\n",
      "Iteration 110, loss = 0.01905371\n",
      "Iteration 111, loss = 0.01876085\n",
      "Iteration 112, loss = 0.01860656\n",
      "Iteration 113, loss = 0.01848655\n",
      "Iteration 114, loss = 0.01834844\n",
      "Iteration 115, loss = 0.01818981\n",
      "Iteration 116, loss = 0.01798523\n",
      "Iteration 117, loss = 0.01783630\n",
      "Iteration 118, loss = 0.01771441\n",
      "Iteration 119, loss = 0.01749814\n",
      "Iteration 120, loss = 0.01738339\n",
      "Iteration 121, loss = 0.01726549\n",
      "Iteration 122, loss = 0.01709638\n",
      "Iteration 123, loss = 0.01698340\n",
      "Iteration 124, loss = 0.01684606\n",
      "Iteration 125, loss = 0.01667016\n",
      "Iteration 126, loss = 0.01654172\n",
      "Iteration 127, loss = 0.01641832\n",
      "Iteration 128, loss = 0.01630111\n",
      "Iteration 129, loss = 0.01623051\n",
      "Iteration 130, loss = 0.01612736\n",
      "Iteration 131, loss = 0.01590220\n",
      "Iteration 132, loss = 0.01582485\n",
      "Iteration 133, loss = 0.01571372\n",
      "Iteration 134, loss = 0.01560349\n",
      "Iteration 135, loss = 0.01557688\n",
      "Iteration 136, loss = 0.01534420\n",
      "Iteration 137, loss = 0.01527883\n",
      "Iteration 138, loss = 0.01517545\n",
      "Iteration 139, loss = 0.01503663\n",
      "Iteration 140, loss = 0.01501192\n",
      "Iteration 141, loss = 0.01482535\n",
      "Iteration 142, loss = 0.01471388\n",
      "Iteration 143, loss = 0.01463948\n",
      "Iteration 144, loss = 0.01454059\n",
      "Iteration 145, loss = 0.01441742\n",
      "Iteration 146, loss = 0.01431741\n",
      "Iteration 147, loss = 0.01428414\n",
      "Iteration 148, loss = 0.01416364\n",
      "Iteration 149, loss = 0.01406742\n",
      "Iteration 150, loss = 0.01402651\n",
      "Iteration 151, loss = 0.01389720\n",
      "Iteration 152, loss = 0.01381412\n",
      "Iteration 153, loss = 0.01371300\n",
      "Iteration 154, loss = 0.01362465\n",
      "Iteration 155, loss = 0.01357048\n",
      "Iteration 156, loss = 0.01348760\n",
      "Iteration 157, loss = 0.01339543\n",
      "Iteration 158, loss = 0.01331941\n",
      "Iteration 159, loss = 0.01320812\n",
      "Iteration 160, loss = 0.01315415\n",
      "Iteration 161, loss = 0.01308279\n",
      "Iteration 162, loss = 0.01302708\n",
      "Iteration 163, loss = 0.01290042\n",
      "Iteration 164, loss = 0.01289267\n",
      "Iteration 165, loss = 0.01277558\n",
      "Iteration 166, loss = 0.01277238\n",
      "Iteration 167, loss = 0.01261308\n",
      "Iteration 168, loss = 0.01260611\n",
      "Iteration 169, loss = 0.01248789\n",
      "Iteration 170, loss = 0.01239662\n",
      "Iteration 171, loss = 0.01231743\n",
      "Iteration 172, loss = 0.01227346\n",
      "Iteration 173, loss = 0.01223136\n",
      "Iteration 174, loss = 0.01217211\n",
      "Iteration 175, loss = 0.01208682\n",
      "Iteration 176, loss = 0.01204707\n",
      "Iteration 177, loss = 0.01200225\n",
      "Iteration 178, loss = 0.01188677\n",
      "Iteration 179, loss = 0.01184993\n",
      "Iteration 180, loss = 0.01175130\n",
      "Iteration 181, loss = 0.01171178\n",
      "Iteration 182, loss = 0.01166052\n",
      "Iteration 183, loss = 0.01163843\n",
      "Iteration 184, loss = 0.01154892\n",
      "Iteration 185, loss = 0.01147629\n",
      "Iteration 186, loss = 0.01142365\n",
      "Iteration 187, loss = 0.01136608\n",
      "Iteration 188, loss = 0.01128053\n",
      "Iteration 189, loss = 0.01128869\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(15,), learning_rate='constant',\n",
       "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento foi extremamente r√°pido, porque a rede neural √© simples e o conjunto de dados de entrada √© pequeno. Agora que a rede foi treinada, vejamos o que pode dizer sobre nossas imagens de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 8, 2, 2, 5, 7, 9, 5,\n",
       "       4, 4, 9, 0, 8, 9, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 3, 0, 1, 2, 3, 4,\n",
       "       5, 6, 7, 8, 5, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp.predict(x_test)\n",
    "predictions[:50] \n",
    "# apenas examinamos os 50 primeiros exemplos na amostra de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essas previs√µes devem estar bastante pr√≥ximas das metas de nossa amostra de treinamento. Vamos verificar a olho nu (compare os valores dessas matrizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 0, 5, 3, 6, 9, 6, 1, 7, 5, 4, 4, 7, 2, 8, 2, 2, 5, 7, 9, 5,\n",
       "       4, 4, 9, 0, 8, 9, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4,\n",
       "       5, 6, 7, 8, 9, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:50] \n",
    "# etiquetas verdadeiras para os primeiros 50 exemplos na amostra de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√£o √© ruim! vemos que a maioria das previs√µes (se n√£o todas) corresponde aos r√≥tulos verdadeiros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas podemos ser um pouco mais quantitativos? Podemos calcular a precis√£o do classificador, qual a probabilidade de um d√≠gito ser classificado na categoria correta. Novamente, o scikit-learn vem com uma ferramenta √∫til para fazer isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9146800501882058"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse n√∫mero √© a probabilidade de os d√≠gitos na amostra de teste serem classificados na categoria correta, o que significa que 91,6% dos d√≠gitos est√£o corretos e 8,4% incorretos.\n",
    "\n",
    "**Conseguimos obter uma precis√£o de 91,6% com esta rede neural muito simples. N√£o √© t√£o ruim!**\n",
    "\n",
    "No entanto, esta √© apenas uma primeira tentativa.\n",
    "\n",
    "Na verdade, devo confessar que optei por usar uma rede simplista para manter o desempenho baixo, para que possamos otimiz√°-lo mais tarde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o e perspectivas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste tutorial pr√°tico, voc√™ aprendeu:\n",
    "\n",
    "* Os princ√≠pios do aprendizado de m√°quina supervisionado para classifica√ß√£o,\n",
    "* Como instalar e usar o pacote python cient√≠fico para aprendizado de m√°quina,\n",
    "* Como investigar sobre seu conjunto de dados de entrada,\n",
    "* Como treinar uma rede neural para reconhecimento de imagens, atingindo uma precis√£o maior que 90% na classifica√ß√£o de d√≠gitos.\n",
    "\n",
    "√â s√≥ o come√ßo! Em posts futuros, iremos:\n",
    "\n",
    "* veja se podemos otimizar nossa rede para aumentar ainda mais a precis√£o,\n",
    "* use aprendizado profundo (redes muito mais complexas) para alcan√ßar precis√£o extrema,\n",
    "* mergulhe um pouco mais no mecanismo do treinamento para entender por que criamos a rede neural com esses par√¢metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
